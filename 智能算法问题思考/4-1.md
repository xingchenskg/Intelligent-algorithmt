### 第4组测验题： ###
4-1、（***）全连接神经网络模型中，我们是如何在网络的输出层，用多个对率回归模型解决的Mnist数据集上的多分类问题呢？还有其它解决方案吗？哪个方案更优呢？
	
	答：
	（1）对数几率回归算法也被也有被直译为逻辑回归。可以用来解决常见的二分类问题，对于多分类问题常用的方法是“拆解法”，将多分类任务拆分为多个二分类任务。先对任务进行拆分，然后为拆分出的每个二分类任务训练一个分类器；在测试时，对这些分类器的结果进行集成以获得最终的多分类结果。常见的策略有一对一，一对多，多对多等策略。
	一对一：每次只能处理两个类别，将两个类别两两配对，会产生n*(n-1)/2个二分类任务。由此训练得到N(N-1)/2个分类器。测试时，测试数据会被送入所有的分类器中，把预测的最多的类别作为最终的结果；在Mnist手写数字识别中一共有10个分类，会产生45个不同的结果，需要45个不同的分类器。训练次数太多，一般不考虑。
	一对多：每次将一个类作为正例、其它类的样例作为反例来训练N个分类器；测试时如果只有一个分类器被预测为正例，则对应的类别作为最终的分类结果，如果有多个分类器预测为正例，则要检测分类器的预测值置信度，置信度最大的类别作为分类结果；
	多对多：若干个类作为正例、若干个作为反例进行训练。常用技术是：纠错输出码，如下：
	编码阶段：对N个类别做M次划分，每次将一部分作为正例、一部分作为反例，从而形成一个二分类训练集，总共形成M个分类器；
	解码阶段：M个分类器分别对测试数据进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终的预测结果。
	（2）其他解决方案：采用Relu激活函数或softmax回归。
	采用ReLU的神经元只需要进行加、乘和比较的操作，计算上更加高效。ReLU函数也被认为具有生物学合理性，比如单侧抑制。在生物神经网络中，同时处于兴奋状态的神经元非常稀疏。Sigmoid型激活函数会导致一个非稀疏的神经网络，而ReLU却具有很好的稀疏性，大约50% 的神经元会处于激活状态。在优化方面，相比于Sigmoid型函数的两端饱和，ReLU函数为左饱和函数，在一定程度上缓解了神经网络的梯度消失问题，加速梯度下降的收敛速度。
	但是通常我们处理多分类任务时常用的是softmax函数，它是二分类函数sigmoid在多分类上的推广类别的概率之和等于1（进行归一化处理），预测结果为非负数，从理论上来讲，它更适合处理多分类问题。
	 
	综上，各有优缺点，在处理多分类一般softmax较为合适
4-2、（**）为什么对率回归模型中，我们要增加一列取值固定为1.0的特征，而在SVM和NN模型中我们并不需要这样做呢？

	答：
	（1）在对数几率回归中，关于回归问题都有偏置，为了方便计算，增加一列固定取值为1.0的特征，设X0为1代入可以直接得到偏置，只剩下未知权重求解
	 
	即求得w0也就是截距，求出偏置了
	（2）knn上面求其它点到样本的的距离，是不需要偏置的，然后svm是需要偏置的，但是我们可以将其简化，考虑w对最大化间隔的影响从而取消偏置对其影响
4-3、（*）就梯度归一化比较对率回归模型和NN模型。

	答：
	对率回归模型：对率回归模型的输出是经过softmax的概率值，概率值的排序不受归一化的影响，对率回归模型的参数优化采用了梯度下降法，如果不对特征进行归一化，可能会使得损失函数值得等高线呈椭球形（个人理解就是不是按照最快梯度下降的方向训练），这样要花费更多的迭代步数才能到达最优解。对率回归模型的损失函数还可以加入正则项，那么参数的大小便决定了损失函数值，特征就有必要先进行归一化。
	KNN模型：用特征计算两个样本间的距离（比如欧氏距离）是kNN的三个基本要素之一。一般来讲不同特征取值范围会不同，为了保证计算欧氏距离时同等对待每个特征，我们有必要把他们的取值范围都缩放到[0,1]之间。更一般的来讲，把特征的取值限定在一个确定的小范围，将有助于机器学习优化算法的更好更快收敛。
4-5、（**）全连接神经网络模型中的对率回归单元都是二分类器吗？为什么？ 
	
	答：
	不是，在利用一对多，以及多对多策略的时候都是多分类器，只有在采用一对一策略时，才是二分类器。
	一对多：每次将一个类作为正例、其它类的样例作为反例来训练N个分类器；测试时如果只有一个分类器被预测为正例，则对应的类别作为最终的分类结果，如果有多个分类器预测为正例，则要检测分类器的预测值置信度，置信度最大的类别作为分类结果；
	多对多：若干个类作为正例、若干个作为反例进行训练。



参考文献：

[1]周志华，机器学习，清华大学出版社，2016

[2]Peter Harrington，机器学习实战，人民邮电出版社，2013

[3]李航，统计学习方法，清华大学出版社，2012

[4] https://blog.csdn.net/qq_45934285/article/details/128066220

[5] https://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html
