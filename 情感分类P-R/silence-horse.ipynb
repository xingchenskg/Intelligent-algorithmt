{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment.binary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13944\\769242377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 加载情感分类数据集和病马数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment.binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'horse-colic.binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# 对率回归的解析解\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\datasets\\_svmlight_format_io.py\u001b[0m in \u001b[0;36mload_svmlight_file\u001b[1;34m(f, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mquery_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         )\n\u001b[0;32m    174\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\datasets\\_svmlight_format_io.py\u001b[0m in \u001b[0;36mload_svmlight_files\u001b[1;34m(files, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         )\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m     ]\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\datasets\\_svmlight_format_io.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         )\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m     ]\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\datasets\\_svmlight_format_io.py\u001b[0m in \u001b[0;36m_open_and_load\u001b[1;34m(f, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    201\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_gen_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m             actual_dtype, data, ind, indptr, labels, query = _load_svmlight_file(\n\u001b[0;32m    204\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultilabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_based\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\datasets\\_svmlight_format_io.py\u001b[0m in \u001b[0;36m_gen_open\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment.binary'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载情感分类数据集和病马数据集\n",
    "X1, y1 = load_svmlight_file('sentiment.binary')\n",
    "X2, y2 = load_svmlight_file('horse-colic.binary')\n",
    "# 对率回归的解析解\n",
    "lr1 = LogisticRegression(solver='liblinear')\n",
    "lr1.fit(X1, y1)\n",
    "lr2 = LogisticRegression(solver='liblinear')\n",
    "lr2.fit(X2, y2)\n",
    "\n",
    "# 对率回归的梯度下降解\n",
    "lr3 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr3.fit(X1, y1)\n",
    "lr4 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr4.fit(X2, y2)\n",
    "\n",
    "# 绘制情感分类数据集上的P-R曲线\n",
    "y_score1 = lr1.decision_function(X1)\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(y1, y_score1)\n",
    "auc1 = auc(recall1, precision1)\n",
    "\n",
    "y_score2 = lr3.decision_function(X1)\n",
    "precision2, recall2, thresholds2 = precision_recall_curve(y1, y_score2)\n",
    "auc2 = auc(recall2, precision2)\n",
    "\n",
    "plt.plot(recall1, precision1, label='Analytical Solution (AUC = %0.2f)' % auc1)\n",
    "plt.plot(recall2, precision2, label='Gradient Descent Solution (AUC = %0.2f)' % auc2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('P-R Curve for Sentiment Classification Dataset')\n",
    "plt.show()\n",
    "\n",
    "# 绘制病马数据集上的P-R曲线\n",
    "y_score3 = lr2.decision_function(X2)\n",
    "precision3, recall3, thresholds3 = precision_recall_curve(y2, y_score3)\n",
    "auc\n",
    "# 比较平衡点\n",
    "import numpy as np\n",
    "f1_scores1 = 2 * precision1 * recall1 / (precision1 + recall1)\n",
    "f1_scores2 = 2 * precision2 * recall2 / (precision2 + recall2)\n",
    "idx1 = np.argmax(f1_scores1)\n",
    "idx2 = np.argmax(f1_scores2)\n",
    "print('Model 1 balance point: precision={:.4f}, recall={:.4f}'.format(precision1[idx1], recall1[idx1]))\n",
    "print('Model 2 balance point: precision={:.4f}, recall={:.4f}'.format(precision2[idx2], recall2[idx2]))\n",
    "\n",
    "# 比较AUC\n",
    "print('Model 1 AUC: {:.4f}'.format(auc1))\n",
    "print('Model 2 AUC: {:.4f}'.format(auc2))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics  import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import hourse,hourse2\n",
    "score ,label = hourse2.f11()\n",
    "precision, recall, thres = precision_recall_curve(label, score)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1.0 / (1 + np.exp(-inX))\n",
    "\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    dataMatrix = np.mat(dataMatIn)                                        \n",
    "    labelMat = np.mat(classLabels).transpose()                            \n",
    "    m, n = np.shape(dataMatrix)                                            \n",
    "    alpha = 0.01                                                        \n",
    "    maxCycles = 500                                                        \n",
    "    weights = np.ones((n,1))\n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(dataMatrix * weights)                                \n",
    "        error = labelMat - h\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error\n",
    "    return weights.getA()                                                \n",
    "\n",
    "def f11():\n",
    "    score,label=[],[]\n",
    "    frTrain = open('horseColicTraining.txt')                                        \n",
    "    frTest = open('horseColicTest.txt')                                                \n",
    "    trainingSet = []; trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[-1]))\n",
    "    trainWeights = gradAscent(np.array(trainingSet), trainingLabels)        \n",
    "    errorCount = 0; numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "        for i in range(len(currLine)-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        score.append(classifyVector(np.array(lineArr), trainWeights[:,0]))\n",
    "        label.append(int(currLine[-1]))\n",
    "    return score,label\n",
    "\n",
    "def classifyVector(inX, weights):\n",
    "    return sigmoid(sum(inX*weights))\n",
    "    if prob > 0.5: return 1.0\n",
    "    else: return 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f11())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
