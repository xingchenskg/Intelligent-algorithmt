代理：

	破解封IP这种反扒机制
	什么是代理：
		代理服务器。
	代理的作用：
		突破自身IP访问限制
		隐藏自身真实IP
	代理ip类型：
		https,http:只能运用到相应协议的url中
	代理ip的匿名度：
		透明：知道使用了代理，也知道真实ip
		匿名：知道使用了代理，不知道真实的ip
		高匿名：不知道使用了代理，更不知道真实ip

多线程使用(不建议)
	
	好处：可以为相关阻塞操作单独开启线程或进程，阻塞操作就可以异步执行。
	弊端：无法无限制的开启多个线程或多个进程

线程池：(适当使用）

	好处：我们可以降低系统对线程或进程创建和销毁的一个频率，从而很好的降低系统开销。
	弊端：池中线程或进程的数量是有上限。

	导入模块：
	from mutiprocessing.jummp import Pool
	实例化对象：(设定线程多少）
	pool=Pool(4)
	pool.map(阻塞函数，丢入线程列表)

3.单线程+异步协成(推荐）

		event_loop:事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上
	当满足某个条件的时候，函数就会被循环执行。
		coroutine:协成对象，我们可以将协成对象注册到事件循环中，它会被事件循环调用。
	我们可以使用async关键字来定义一个方法，这个方法在调用时不会被立即执行，而是返回一个协成对象。
		task:任务，它是对协成对象的进一步封装，包含了任务的各个状态。
		future:代表将来要执行或还没有执行的任务，实际上和task没有本质区别。
		async:定义一个协程。
		await:用来挂起阻塞方法的执行。
协程示例：

	导入模块：
		import asyncio
		async def request(url):
			print('正在请求的url',url)
			print('请求成功’，url）
		async修饰的函数，调用之后会返回的一个协成对象
		c=request('www.baidu.com')
		创建事件循环对象
		loop=asyncio.get_event_loop()
		将协成对象注册到loop中，然后启动loop
		loop.run_until_complete(c)


		task的使用：
		import asyncio
		async def request(url):
			print('正在请求的url',url)
			print('请求成功’，url）
		async修饰的函数，调用之后会返回的一个协成对象
		c=request('www.baidu.com')
		loop=asyncio.get_event_loop()
		基于loop创建一个task对象
		task=loop.create_task(c)
		print(task)
		loop.run_util_complete(task)
		print(task)

		future的使用：
		loop=asyncio.get_event_loop()
		task=asyncio.ensure_future(c)
		loop.run_until_complete(task)

绑定回调
	def callback_func(task):
		result返回的就是任务对象种封装的协成对象对应函数的返回值
		print(task.result())

	loop.asyncio.get_event_loop()
	task=loop.create_task(c)
	将回调函数绑定到任务对象中
	task.add_done_callback(callback_func)
	loop.run_until_complete(task)

实列：

	import asyncio
	import time
	async def request(url):
			print('正在下载',url)
			在异步协程中如果出现同步模块相关代码，那么就无法实现异步
			//time.sleep(2)
			当在asyncio中玉带阻塞操作必须进行手动挂起
			await asyncio.sleep(2)
			print('下载完成',url)
	start=time.time()
	urls=[
		'www.baidu.com',
		'www.sougou.com',
		'www.goubanjia.com'
		]
	tasks=[]
	for url in urls:
		c=request(url)
		task=asyncio.ensure_future(c)
		tasks.append(task)
	loop=loop.get_event_loop()
	loop.run_until_complete(tasks.wait(tasks))
	print(time.time()-start)

实列二：

创建服务器：
	from flask import Flask
	import time
	app=Flask(__name__)


	@app.route('/sky')
	def index__sky():
		time.sleep(2)
		return 'Hello sky'

	@app.route('/bobo')
	def index__bobo('/bobo'):
		time.sleep(2)
		return 'Hello bobo'

	@app.route('/joy')
	def index__joy():
		time.sleep(2)
		return 'Hello joy'

	if __name__(main)

多任务异步爬虫：

	import aiohttp
	import requests
	import time 

	urls=['http:/127.0.0.1:5000/sky'，'http:/127.0.0.1:5000/bobo，'http:/127.0.0.1:5000/joy']

	start=time.time()
	async def get_page(url):
			async with aiohttp.ClientSession() as session:
					get(),post()
					hearders进行url伪装param/data,代理IP:proxy='https://'
					async await session.get(url) as response:
					text()返回字符串形式的响应数据
					read()返回的是二进制形式的响应数据
					json()返回的是json对象
					在获取响应数据之前一定要用await手动挂起
					page_text=await response.text()
					print(page_text)
	tasks=[]
	for url in urls:
		c=get_event_loop(url)
		task=asyncio.ensure.future(c)
	tasks.append(task)

	loop=asyncio.get_event_loop()
	loop.run_until_complete(asyncio.wait(tasks))
	end=time.time()
	print('总耗时：',end-start)