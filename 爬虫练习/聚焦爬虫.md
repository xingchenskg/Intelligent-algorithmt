数据解析的分类：

	正则表达
	bs4
	xpath

数据解析原理概述：

	解析的局部文本类容都会在标签之间或者标签对应的属性中进行存储
	进行指定标签的定位
	标签或者标签对应的属性中存储的数据值进行提取

	正则解析：
	
	bs4进行数据解析
		数据解析的原理：
		1.标签定位
		2.提取标签，标签属性中存储的数据值
	bs4数据解析的原理：
		1.实例化一个BeautifulSoup对象，并将页面源码加载到该对象中去
		2.通过调用BeautifulSoup对象中的相关属性或者方法进行标签定位和数据提取
	环境安装：
		pip install bs4
		pip install lxml
	如何实例化BeautifulSoup
		1.将本地html文档中的数据加载到该对象中
			fp=open('./test.gtml','r',encodinh='utf-8')
			soup=BeautifulSoup(fp,'lxml')
		2.将互联网中的页面数据加载到该对象中
			page_text=response.text
			soup=Beautiful(page_text,'lxml')
		提供的属性和方法：
			soup.tagName：返回回的是第一次出现的tagname
			soup.find():
				find('tagname'):等同于soup.div
				属性定位：
					find('div'，class_=/id_/atttr_='song')
			soup.find_all('tagname'):返回所有标签
			soup.select('模中选择器（id,class,标签）')
			层级选择器：
				soup.select('.tang>ul>li a')[0]空格表示多个层级，>表示一个层级
			获取标签之间的文本的数据
				soup.a.text/string/get_text()
				text/get_text()可以获取所有的文本内容
				string只能获取直系标签中的文本内容
			获取标签中的属性值
				soup.a['href']
xpath解析：最常用且最便捷的一种解析方式，通用性

	xpath解析原理
		1.实例化一个etree的对象，且需要将源码数据加载到该对象中
		2.调用etree的对象中的xpath方法结合着xpath表达式实现标签定位和内容的捕获
	环境安装
		pip install lxml
	如何实例化一个etree对象
			from lxml import etree
		1.将本地的html文档中的源码数据加载到etree对象中
			etree.parse(filePath)
		2.可以将从互联网上获取源码数据加载到该对象中
			etree.HTMl('page_text')
		xpath('xpath表达式')
			/表示从根节点开始定位，表示一个层级
			//表示多个层级，可以表示从任意位置开始定位
		属性定位
			xpath('div[@class="song"]')
		索引定位
			div[@class="song"]/p[3]:索引从1开始
		取文本
			/text()直系文本数据
			//text()标签中所有非直系文本内容
		取属性
			/@attrName  ==>img/src
		
获取数据出现中文乱码

	response=request.get()
	response.encoding='utf-8'
	response.text
	或者
	对乱码具体位置(通用解决方法）
	img_name.encode('iso-8859-1').decode('gbk')
同时定位两个xpath层级不同中间用与|隔开


	